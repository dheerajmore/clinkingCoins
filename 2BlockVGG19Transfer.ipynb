{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras.layers import Input\n",
    "\n",
    "\n",
    "img_width, img_height = 100, 100\n",
    "train_data_dir = \"data/train\"\n",
    "validation_data_dir = \"data/val\"\n",
    "nb_train_samples = 326\n",
    "nb_validation_samples = 66 \n",
    "batch_size = 5\n",
    "epochs = 50\n",
    "\n",
    "### Build the network \n",
    "img_input = Input(shape=(img_width, img_height, 3))\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "model = Model(inputs = img_input, outputs = x)\n",
    "\n",
    "#Print model summary\n",
    "model.summary()\n",
    "\n",
    "#Create a dictionary with layer name\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "[layer.name for layer in model.layers]\n",
    "\n",
    "#Use pretrained weights from the downloaed VGG19 model h5 file.\n",
    "#Use pretrained weights from the downloaed VGG19 model h5 file.\n",
    "import h5py\n",
    "weights_path = 'vgg19_weights.h5' # ('https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5)\n",
    "f = h5py.File(weights_path)\n",
    "list(f.keys())\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Here we are extracting model_weights for each and every layer from the .h5 file\n",
    "# With a for loop we can set_weights for the entire network.\n",
    "for i in layer_dict.keys():\n",
    "    if (i.startswith(\"input\")):\n",
    "        continue\n",
    "    else:\n",
    "        weight_names = f[i].attrs[\"weight_names\"]\n",
    "        weights = [f[i][j] for j in weight_names]\n",
    "        index = layer_names.index(i)\n",
    "        #print(\"Before\" + model.layers[index].name)\n",
    "        #print(model.layers[index].get_weights())\n",
    "        model.layers[index].set_weights(weights)\n",
    "        #print(\"After\")\n",
    "        #print(model.layers[index].get_weights())\n",
    "        \n",
    "        # Freeze the layers which you don't want to train. Here I am freezing all layers.\n",
    "        model.layers[index].trainable = False\n",
    "\n",
    "#Print the model so far\n",
    "model.summary()\n",
    "\n",
    "#Adding the trainable fully connected  Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "#Print the final model\n",
    "model_final.summary()\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.01, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.3,\n",
    "width_shift_range = 0.3,\n",
    "height_shift_range=0.3,\n",
    "rotation_range=30)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size, \n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "# Save the model according to the conditions  \n",
    "checkpoint = ModelCheckpoint(\"vgg19_2BlockTransfer.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "# Train the model \n",
    "model_final.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch = nb_train_samples//batch_size,\n",
    "epochs = epochs,\n",
    "validation_data = validation_generator,\n",
    "validation_steps=nb_validation_samples // batch_size,\n",
    "callbacks = [checkpoint, early])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model and Visualize the network\n",
    "from keras.models import load_model\n",
    "modelLoaded = load_model('vgg19_2BlockTransfer.h5')\n",
    "from quiver_engine.server import launch\n",
    "from gevent.pywsgi import WSGIServer\n",
    "launch(modelLoaded, input_folder='./', port=7002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict dollar value class for a sample image\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg19 import decode_predictions\n",
    "modelLoaded = load_model('vgg19_2BlockTransfer.h5')\n",
    "#load the image\n",
    "imageLoaded = load_img('IMG_0878.jpg', target_size=(100, 100))\n",
    "# convert the image pixels to a numpy array\n",
    "imageLoaded = img_to_array(imageLoaded)\n",
    "# reshape data for the model\n",
    "imageLoaded = imageLoaded.reshape((1, imageLoaded.shape[0], imageLoaded.shape[1], imageLoaded.shape[2]))\n",
    "# predict the probability across all output classes\n",
    "prediction = modelLoaded.predict(imageLoaded)\n",
    "# Print the prediction\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
